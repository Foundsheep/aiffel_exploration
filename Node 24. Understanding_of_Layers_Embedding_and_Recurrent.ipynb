{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "departmental-excess",
   "metadata": {},
   "source": [
    "# 학습 목표\n",
    "\n",
    "- 레이어의 개념을 이해한다.\n",
    "- 딥러닝 모델 속 각 레이어(Embedding, RNN, LSTM)의 동작 방식을 이해한다.\n",
    "- 데이터의 특성을 고려한 레이어를 설계하고, 이를 Tensorflow로 정의하는 법을 배운다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-ensemble",
   "metadata": {},
   "source": [
    "## 분포 가설과 분산 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-apple",
   "metadata": {},
   "source": [
    "### 단어의 분산 표현(Distributed Representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-huntington",
   "metadata": {},
   "source": [
    "- Sparse Representation은 벡터 차원에 의미를 둬서 그에 맞게 단어들을 매핑하는 것\n",
    "- 그러나 Distributed Representation은 그렇게 의미를 부여하지 않음\n",
    "- 대신 문맥에서 나타나는 위치를 토대로 `'유사한 맥락에서 동일한 위치에 나오면 의미가 비슷할 것이다'`라는 분포 가설(distribution hypothesis)를 따라서 단어들의 벡터를 만듦\n",
    "- 이 때 벡터의 차원은 고정시킴\n",
    "- 그래서 유사한 문맥에서 동일한 위치에 나오는 단어들은 벡터로 표현했을 때 서로 거리를 가깝게 해주는 게 Distributed Representation의 핵심\n",
    "- 그리고 벡터의 차원들은 각각 특정 의미를 내포한다라기 보다 그냥 차원 전체(벡터 전체)에 있어서 그 의미가 고루 퍼져 있다라고 여길 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-gardening",
   "metadata": {},
   "source": [
    "> #### 이렇게 그냥 n개 단어로, k차원을 가진 벡터들을 만드는 걸 `Embedding`레이어가 한다.\n",
    "> #### 그리고 우린 그냥 n과 k만 정해주면 된다.\n",
    "> #### 그리고 여기서 `Embedding` 레이어는 그 벡터들(단어 사전)을 만드는 게 일인데, 그 단어 사전 자체가 Weight, 즉 파라미터이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-external",
   "metadata": {},
   "source": [
    "## 단어를 부탁해! Embedding 레이어"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-execution",
   "metadata": {},
   "source": [
    "- 단어사전의 사이즈를 우리가 정해준다.\n",
    "- 그리고 이 사이즈가 곧 Weight의 크기이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-dubai",
   "metadata": {},
   "source": [
    "#### Lookup table\n",
    "- 저 weight이 담긴 단어 사전(즉, n개의 단어 x k개의 차원)은 추후 알고 싶은 단어의 벡터를 뽑아온다는 의미에서 Lookup table로도 불린단다.\n",
    "- 그리고 이렇게 단어사전에 word -> vector로 만드는 과정이 바로 핵심!\n",
    "- 그리고 그 핵심 원리의 기본은 one-hot encoding!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-seattle",
   "metadata": {},
   "source": [
    "#### one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-strengthening",
   "metadata": {},
   "source": [
    "- 단점이 있는데,\n",
    "- 내적의 값이 0인 벡터들(직교하는 벡터들)은 1과 1이 만나는 지점이 없는 서로 독립된 단어가 된다.(그런데 이들끼리 연관이 있으면...?)\n",
    "- 차원의 저주도 있다.\n",
    "  - 단어 수만큼 차원이 늘어나면 골치 아프다.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-blogger",
   "metadata": {},
   "source": [
    "#### 실험! - one-hot encoding을 linear layer로 적용해보기\n",
    "재밌는 상상을 한 번 해봅시다. 선형변환 담당 Linear 레이어를 잊지 않았죠? 원-핫 인코딩에 Linear 레이어를 적용하면 어떻게 될까요? 단 하나의 인덱스만 1이고 나머지가 모두 0인 극단적인 벡터지만 어쨌건 고차원 벡터이니 적용해 볼 수 있잖아요! 백문이 불여일견, 소스로 한 번 확인해 보죠, 우선 원-핫 벡터를 먼저 생성합니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "extended-astrology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "vocab = {      # 사용할 단어 사전 정의\n",
    "    \"i\": 0,\n",
    "    \"need\": 1,\n",
    "    \"some\": 2,\n",
    "    \"more\": 3,\n",
    "    \"coffee\": 4,\n",
    "    \"cake\": 5,\n",
    "    \"cat\": 6,\n",
    "    \"dog\": 7\n",
    "}\n",
    "\n",
    "sentence = \"i i i i need some more coffee coffee coffee\"\n",
    "# 위 sentence\n",
    "_input = [vocab[w] for w in sentence.split()]  # [0, 0, 0, 0, 1, 2, 3, 4, 4, 4]\n",
    "\n",
    "vocab_size = len(vocab)   # 8\n",
    "\n",
    "one_hot = tf.one_hot(_input, vocab_size)\n",
    "print(one_hot.numpy())    # 원-핫 인코딩 벡터를 출력해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "limiting-institute",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 8), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-atmosphere",
   "metadata": {},
   "source": [
    "> tf.one_hot()은 정수로 된 어레이를 받아서 해당 정수에 맞게 one-hot encoding된 행렬을 내뱉어 준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-manhattan",
   "metadata": {},
   "source": [
    "어때요, 원-핫 인코딩의 결과가 여러분이 상상한 것과 동일한가요? 이제 생성된 원-핫 벡터를 Linear 레이어에 넣어보죠. 놀라운 결과가 기다리고 있답니다..!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "verified-factory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Weight\n",
      "[[-0.05541933  0.7289257 ]\n",
      " [ 0.5526576   0.17332882]\n",
      " [-0.4281848   0.04122239]\n",
      " [-0.6178259   0.38403618]\n",
      " [ 0.6672548  -0.6742032 ]\n",
      " [-0.05171949 -0.08872664]\n",
      " [ 0.7648511  -0.4172705 ]\n",
      " [ 0.06281644  0.6062473 ]]\n",
      "\n",
      "One-Hot Linear Result\n",
      "[[-0.05541933  0.7289257 ]\n",
      " [-0.05541933  0.7289257 ]\n",
      " [-0.05541933  0.7289257 ]\n",
      " [-0.05541933  0.7289257 ]\n",
      " [ 0.5526576   0.17332882]\n",
      " [-0.4281848   0.04122239]\n",
      " [-0.6178259   0.38403618]\n",
      " [ 0.6672548  -0.6742032 ]\n",
      " [ 0.6672548  -0.6742032 ]\n",
      " [ 0.6672548  -0.6742032 ]]\n"
     ]
    }
   ],
   "source": [
    "distribution_size = 2   # 보기 좋게 2차원으로 분산 표현하도록 하죠!\n",
    "linear = tf.keras.layers.Dense(units=distribution_size, use_bias=False)\n",
    "one_hot_linear = linear(one_hot)\n",
    "\n",
    "print(\"Linear Weight\")\n",
    "print(linear.weights[0].numpy())\n",
    "\n",
    "print(\"\\nOne-Hot Linear Result\")\n",
    "print(one_hot_linear.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-chemical",
   "metadata": {},
   "source": [
    "> #### note:\n",
    "> - 위의 인풋 데이터와 Dense layer를 지난 아웃풋을 비교해보면\n",
    "> - 1이 있는 자리(즉, 정수 인코딩에서 1이 있는 자리)만 가중치와 곱해져서 나온 것을 알 수 있다.\n",
    "> - 이런 식으로 문장을 정수 인코딩(단어 사전의 인덱스)해주고 모델에 넣으면 사실 `Embedding` 레이어는 정수 인코딩을 one-hot encoding으로 바꾸고 선형변환을 통해 의미를 가진 벡터를 만들어낸단다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "polish-quarter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(8, 2) dtype=float32, numpy=\n",
       " array([[-0.05541933,  0.7289257 ],\n",
       "        [ 0.5526576 ,  0.17332882],\n",
       "        [-0.4281848 ,  0.04122239],\n",
       "        [-0.6178259 ,  0.38403618],\n",
       "        [ 0.6672548 , -0.6742032 ],\n",
       "        [-0.05171949, -0.08872664],\n",
       "        [ 0.7648511 , -0.4172705 ],\n",
       "        [ 0.06281644,  0.6062473 ]], dtype=float32)>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sealed-lawsuit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\n",
       "array([[-0.05541933,  0.7289257 ],\n",
       "       [-0.05541933,  0.7289257 ],\n",
       "       [-0.05541933,  0.7289257 ],\n",
       "       [-0.05541933,  0.7289257 ],\n",
       "       [ 0.5526576 ,  0.17332882],\n",
       "       [-0.4281848 ,  0.04122239],\n",
       "       [-0.6178259 ,  0.38403618],\n",
       "       [ 0.6672548 , -0.6742032 ],\n",
       "       [ 0.6672548 , -0.6742032 ],\n",
       "       [ 0.6672548 , -0.6742032 ]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-steel",
   "metadata": {},
   "source": [
    "#### tensorflow에서 임베딩 레이어 선언하는 법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "attached-theory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding을 진행할 문장: (1, 3)\n",
      "Embedding된 문장: (1, 3, 100)\n",
      "Embedding Layer의 Weight 형태: (64, 100)\n"
     ]
    }
   ],
   "source": [
    "some_words = tf.constant([[3, 57, 35]])\n",
    "# 3번 단어 / 57번 단어 / 35번 단어로 이루어진 한 문장입니다.\n",
    "\n",
    "print(\"Embedding을 진행할 문장:\", some_words.shape)\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=64, output_dim=100)\n",
    "# 총 64개의 단어를 포함한 Embedding 레이어를 선언할 것이고,\n",
    "# 각 단어는 100차원으로 분산 표현 할 것입니다.\n",
    "\n",
    "print(\"Embedding된 문장:\", embedding_layer(some_words).shape)\n",
    "print(\"Embedding Layer의 Weight 형태:\", embedding_layer.weights[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "modified-software",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=int32, numpy=array([[ 3, 57, 35]], dtype=int32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-montana",
   "metadata": {},
   "source": [
    "#### 임베딩 레이어의 주의사항\n",
    "> #### note:\n",
    "> - 해당 레이어는 그냥 단어를 대응해준 레이어에 불과해서 미분이 안된단다.\n",
    "> - 따라서 신경망에 붙일 때 `어떤 연산 결과를 임베딩 레이어에 붙이는 것`은 불가능하다.\n",
    "> - 그래서 `입력에 직접 연결해서 쓴다.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-smooth",
   "metadata": {},
   "source": [
    "## 순차적인 데이터! Recurrent 레이어 (1) RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-sacramento",
   "metadata": {},
   "source": [
    "- RNN의 입력으로 들어가는 `모든 단어만큼 Weight를 만드는 게 아님에 유의`\n",
    "- `(입력의 차원, 출력의 차원)`에 해당하는 단 하나의 Weight를 순차적으로 업데이트하는 것이 RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-rocket",
   "metadata": {},
   "source": [
    "#### 코드로 구현하는 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "decreased-triple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN에 입력할 문장: What time is it ?\n",
      "Embedding을 위해 단어 매핑: [[2 3 0 1 4]]\n",
      "입력 문장 데이터 형태: (1, 5)\n",
      "\n",
      "Embedding 결과: (1, 5, 100)\n",
      "Embedding Layer의 Weight 형태: (5, 100)\n",
      "\n",
      "RNN 결과 (모든 Step Output): (1, 5, 64)\n",
      "RNN Layer의 Weight 형태: (100, 64)\n",
      "\n",
      "RNN 결과 (최종 Step Output): (1, 64)\n",
      "RNN Layer의 Weight 형태: (100, 64)\n"
     ]
    }
   ],
   "source": [
    "sentence = \"What time is it ?\"\n",
    "dic = {\n",
    "    \"is\": 0,\n",
    "    \"it\": 1,\n",
    "    \"What\": 2,\n",
    "    \"time\": 3,\n",
    "    \"?\": 4\n",
    "}\n",
    "\n",
    "print(\"RNN에 입력할 문장:\", sentence)\n",
    "\n",
    "sentence_tensor = tf.constant([[dic[word] for word in sentence.split()]])\n",
    "\n",
    "print(\"Embedding을 위해 단어 매핑:\", sentence_tensor.numpy())\n",
    "print(\"입력 문장 데이터 형태:\", sentence_tensor.shape)\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=len(dic), output_dim=100)\n",
    "emb_out = embedding_layer(sentence_tensor)\n",
    "\n",
    "print(\"\\nEmbedding 결과:\", emb_out.shape)\n",
    "print(\"Embedding Layer의 Weight 형태:\", embedding_layer.weights[0].shape)\n",
    "\n",
    "rnn_seq_layer = \\\n",
    "tf.keras.layers.SimpleRNN(units=64, return_sequences=True, use_bias=False)\n",
    "rnn_seq_out = rnn_seq_layer(emb_out)\n",
    "\n",
    "print(\"\\nRNN 결과 (모든 Step Output):\", rnn_seq_out.shape)\n",
    "print(\"RNN Layer의 Weight 형태:\", rnn_seq_layer.weights[0].shape)\n",
    "\n",
    "rnn_fin_layer = tf.keras.layers.SimpleRNN(units=64, use_bias=False)\n",
    "rnn_fin_out = rnn_fin_layer(emb_out)\n",
    "\n",
    "print(\"\\nRNN 결과 (최종 Step Output):\", rnn_fin_out.shape)\n",
    "print(\"RNN Layer의 Weight 형태:\", rnn_fin_layer.weights[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "norman-render",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[2, 3, 0, 1, 4]], dtype=int32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "outer-cherry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5, 64), dtype=float32, numpy=\n",
       "array([[[ 3.41891013e-02, -2.78892722e-02, -3.07099316e-02,\n",
       "         -3.12659726e-03,  5.28826229e-02, -1.27824536e-02,\n",
       "         -1.09696081e-02,  4.05459702e-02, -3.42771746e-02,\n",
       "         -6.42082328e-03, -6.06246106e-02, -1.71578042e-02,\n",
       "         -3.97295617e-02, -3.13773449e-03, -2.22241431e-02,\n",
       "         -4.83743623e-02,  2.03773677e-02,  4.20067497e-02,\n",
       "         -1.15800295e-02,  1.25815263e-02,  6.79355767e-03,\n",
       "          3.30978297e-02, -3.94702666e-02,  3.20414379e-02,\n",
       "          2.69302558e-02,  4.19907235e-02,  6.41035568e-03,\n",
       "         -3.24814431e-02,  5.22524863e-02, -1.66594516e-02,\n",
       "          4.97148372e-03, -6.90012844e-03,  2.34572720e-02,\n",
       "          4.23527025e-02,  6.31098822e-03,  1.52858943e-02,\n",
       "          9.05076601e-03,  4.98658456e-02, -3.10697220e-02,\n",
       "         -1.17295736e-03, -9.48296674e-03, -5.86851835e-02,\n",
       "          3.02995816e-02,  1.87483709e-02, -2.86785164e-03,\n",
       "         -3.67441075e-03,  2.16524452e-02,  8.35795701e-03,\n",
       "         -1.74132176e-02,  3.59597169e-02, -2.54062749e-03,\n",
       "         -1.89931728e-02, -3.68635617e-02,  1.21075856e-02,\n",
       "         -3.35060470e-02,  6.00739866e-02,  3.23891900e-02,\n",
       "         -2.63948832e-02,  3.46007035e-03,  1.39563316e-02,\n",
       "         -2.99088564e-02,  3.14023793e-02,  1.42550031e-02,\n",
       "         -1.57243144e-02],\n",
       "        [-1.34637244e-02,  2.90215593e-02, -2.69424506e-02,\n",
       "         -6.77697062e-02, -2.57123890e-03, -5.16075753e-02,\n",
       "          7.66139403e-02, -2.09622569e-02, -2.84435991e-02,\n",
       "          4.06413600e-02,  4.52578114e-03, -8.56833607e-02,\n",
       "          6.66230470e-02, -3.79542783e-02,  8.21824884e-04,\n",
       "         -4.63636182e-02,  5.32898260e-03,  3.05892620e-02,\n",
       "         -1.60826128e-02, -1.03006750e-01,  1.08389392e-01,\n",
       "         -1.76250804e-02,  2.77229585e-02,  6.66738674e-02,\n",
       "          3.84124517e-02, -8.93324539e-02,  3.63503471e-02,\n",
       "         -1.13031462e-01,  2.46995483e-02, -4.14594524e-02,\n",
       "         -6.73554242e-02, -9.16913226e-02, -3.63103263e-02,\n",
       "          1.14987446e-02,  5.12550920e-02, -3.54508273e-02,\n",
       "         -2.87244618e-02,  4.13000882e-02, -2.38034949e-02,\n",
       "          4.34596017e-02,  2.83971280e-02, -1.87106244e-02,\n",
       "          4.92471829e-02, -9.26129706e-03,  5.04600927e-02,\n",
       "          1.43888406e-02, -7.42968842e-02,  2.72131208e-02,\n",
       "          7.47567508e-03, -2.21553799e-02,  1.55005930e-02,\n",
       "         -3.90763469e-02, -2.26951651e-02, -1.46025675e-03,\n",
       "         -1.41932266e-02, -2.15383675e-02,  7.76740015e-02,\n",
       "          6.31541759e-02, -2.90230364e-02,  4.18449976e-02,\n",
       "          2.19167047e-03,  3.85457873e-02,  2.95921247e-02,\n",
       "         -6.22668751e-02],\n",
       "        [ 6.78756693e-03, -9.15391594e-02, -2.16472335e-02,\n",
       "         -5.68782492e-03,  4.61450033e-02, -7.59595782e-02,\n",
       "          3.76586849e-03, -6.53928611e-03, -3.20705622e-02,\n",
       "          2.57059019e-02,  1.03087991e-01,  1.30792782e-02,\n",
       "          4.49807830e-02, -7.75963813e-02,  3.22824297e-03,\n",
       "          2.89903511e-03, -3.75329517e-02, -1.31317511e-01,\n",
       "         -7.65483379e-02, -5.39908968e-02,  1.32158980e-01,\n",
       "         -3.52582075e-02,  4.05042358e-02, -6.55806996e-03,\n",
       "         -4.11926322e-02,  3.64429988e-02, -2.66150795e-02,\n",
       "         -1.57338437e-02, -3.71133424e-02,  7.52512440e-02,\n",
       "         -4.65382710e-02,  7.20314831e-02, -5.61599843e-02,\n",
       "          5.05798459e-02, -7.33126700e-03,  1.37082756e-01,\n",
       "         -6.13606675e-03,  1.24215998e-03,  6.46205246e-02,\n",
       "          6.95438124e-03, -4.68724454e-03,  9.00064316e-03,\n",
       "         -4.93867770e-02, -7.47595578e-02,  1.53826037e-03,\n",
       "         -7.86579866e-03,  1.12516331e-02,  9.40627325e-03,\n",
       "         -3.07888654e-03, -1.95588078e-02,  4.99909185e-02,\n",
       "         -1.43577706e-03,  5.60329929e-02, -1.11928759e-02,\n",
       "          7.09765926e-02, -1.31558180e-01,  1.37847094e-02,\n",
       "         -9.36210155e-02, -3.07838414e-02,  9.63999331e-02,\n",
       "          2.64107734e-02,  5.88838905e-02, -2.25364156e-02,\n",
       "         -8.86650458e-02],\n",
       "        [ 2.20730416e-02,  5.96066006e-02, -1.06032588e-01,\n",
       "         -2.53332444e-02,  2.96941157e-02,  4.48713778e-03,\n",
       "         -7.23432424e-03, -6.28474578e-02,  5.72660714e-02,\n",
       "         -2.98614334e-02,  2.43898183e-02,  1.94692295e-02,\n",
       "          1.81136746e-02,  2.19422858e-02,  9.53413248e-02,\n",
       "         -7.69014359e-02, -1.75498414e-03, -1.93342883e-02,\n",
       "         -3.79829295e-02,  9.64927748e-02,  9.14800819e-03,\n",
       "          1.33678112e-02, -6.65108711e-02, -8.84507075e-02,\n",
       "         -3.14035080e-02,  8.27369615e-02,  1.78904012e-01,\n",
       "         -1.02213807e-02, -9.24604237e-02,  7.48380944e-02,\n",
       "          5.74463047e-02,  7.36216456e-02,  1.37927188e-02,\n",
       "         -1.80598777e-02, -3.03920023e-02, -4.68341559e-02,\n",
       "         -3.26475948e-02,  2.83283032e-02,  5.86294271e-02,\n",
       "         -1.60479881e-02,  4.29455340e-02, -5.41322343e-02,\n",
       "          3.12484498e-03,  8.32668319e-02,  1.02881854e-03,\n",
       "          2.09592283e-04,  1.48264319e-01, -2.16622446e-02,\n",
       "         -9.05795489e-03,  7.41409287e-02,  9.20931995e-02,\n",
       "          3.62776369e-02, -6.18428923e-02,  3.55441496e-02,\n",
       "         -1.43032148e-02, -5.24250679e-02,  2.97966115e-02,\n",
       "          1.88881576e-01, -6.85502738e-02,  3.80697250e-02,\n",
       "          2.14829319e-03, -8.10656399e-02,  7.94682279e-02,\n",
       "         -8.28764215e-02],\n",
       "        [ 3.64758223e-02, -1.22042269e-01, -2.87645147e-03,\n",
       "         -2.75817327e-02, -3.34120020e-02,  1.61044095e-02,\n",
       "          2.43461095e-02, -5.01771681e-02,  9.07544121e-02,\n",
       "         -4.88095321e-02, -5.87375723e-02, -6.31798664e-03,\n",
       "         -4.42741290e-02,  4.29296568e-02,  4.80999984e-03,\n",
       "         -4.65796217e-02, -9.87087190e-03, -1.62399739e-01,\n",
       "          1.93006024e-02,  4.01485227e-02, -4.46089692e-02,\n",
       "         -3.97693701e-02,  6.76021725e-02, -3.17575480e-03,\n",
       "          1.09066322e-01,  2.23837346e-02, -3.59008946e-02,\n",
       "         -8.40917751e-02,  5.40940538e-02, -2.48199198e-02,\n",
       "         -1.44435823e-01, -7.45792463e-02,  7.38670081e-02,\n",
       "          4.06978428e-02,  2.75133103e-02, -1.24800736e-02,\n",
       "          1.33005083e-01, -1.82538051e-02, -3.45587879e-02,\n",
       "         -1.27438918e-01,  2.16394402e-02, -2.81124767e-02,\n",
       "          2.24527135e-01,  5.00645898e-02,  1.47781298e-01,\n",
       "          1.40255187e-02,  3.38758552e-03, -8.73881206e-02,\n",
       "          3.75388525e-02,  3.72333340e-02, -5.79892322e-02,\n",
       "         -8.33167285e-02, -1.94915999e-02,  3.85577157e-02,\n",
       "         -1.19589893e-02, -9.58862063e-03, -5.87022956e-03,\n",
       "         -4.14557308e-02, -5.41279726e-02,  1.29776224e-01,\n",
       "          9.41374749e-02, -2.90074274e-02,  4.34768349e-02,\n",
       "         -1.23980507e-01]]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_seq_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-tender",
   "metadata": {},
   "source": [
    "#### 위의 코드를 lstm으로 구현해보기(동일함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "gentle-cologne",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "\n",
      "LSTM 결과 (모든 Step Output): (1, 5, 64)\n",
      "LSTM Layer의 Weight 형태: (100, 256)\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "\n",
      "LSTM 결과 (최종 Step Output): (1, 64)\n",
      "LSTM Layer의 Weight 형태: (100, 256)\n"
     ]
    }
   ],
   "source": [
    "lstm_seq_layer = tf.keras.layers.LSTM(units=64, return_sequences=True, use_bias=False)\n",
    "lstm_seq_out = lstm_seq_layer(emb_out)\n",
    "\n",
    "print(\"\\nLSTM 결과 (모든 Step Output):\", lstm_seq_out.shape)\n",
    "print(\"LSTM Layer의 Weight 형태:\", lstm_seq_layer.weights[0].shape)\n",
    "\n",
    "lstm_fin_layer = tf.keras.layers.LSTM(units=64, use_bias=False)\n",
    "lstm_fin_out = lstm_fin_layer(emb_out)\n",
    "\n",
    "print(\"\\nLSTM 결과 (최종 Step Output):\", lstm_fin_out.shape)\n",
    "print(\"LSTM Layer의 Weight 형태:\", lstm_fin_layer.weights[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-arena",
   "metadata": {},
   "source": [
    "> #### 아이펠 설명\n",
    "> 처음 보는 LSTM이라는 레이어가 등장했습니다!   \n",
    "> Embedding 벡터의 차원수(unit)의 크기가 동일할 경우`(위 예에서는 units=64)`, Weight의 크기가 위에서 사용했던 SimpleRNN의 4배나 되는 것을 볼 수 있는데, 왜 이런 RNN 레이어가 등장하게 된 것일까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-timeline",
   "metadata": {},
   "source": [
    "## 순차적인 데이터! Recurrent 레이어 (2) LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-static",
   "metadata": {},
   "source": [
    "#### 아이펠 설명 \n",
    "\n",
    "LSTM 은 기본적인 바닐라(Simple) RNN보다 4배나 큰 Weight를 가지고 있음을 이전 스텝에서 확인했죠? 4배 깊은 RNN이라고 표현하기보다, 4종류의 서로 다른 Weight를 가진 RNN이라고 이해하시는 것이 좋습니다. 각 Weight들은 Gate라는 구조에 포함되어 어떤 정보를 기억하고, 어떤 정보를 다음 스텝에 전달할지 등을 결정합니다!\n",
    "\n",
    "LSTM에는 Cell state 라는 새로운 개념이 추가되는데, 긴 문장이 들어와도 이 Cell state 를 통해 오래된 기억 또한 큰 손실 없이 저장해줍니다. 위의 두 번째 참고 링크를 보시면 수식으로도 이해하실 수 있을 것입니다. 그리고 앞서 언급한 Gate 들이 Cell state에 정보를 추가하거나 빼주는 역할을 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-novelty",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-adolescent",
   "metadata": {},
   "source": [
    "#### 아이펠 설명 \n",
    "\n",
    "\n",
    "LSTM은 GRU에 비해 Weight가 많기 때문에 충분한 데이터가 있는 상황에 적합하고, 반대로 GRU는 적은 데이터에도 웬만한 학습 성능을 보여주죠. 이것저것 사용해보며 여러분의 프로젝트에 적합한 레이어를 찾아보세요!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-converter",
   "metadata": {},
   "source": [
    "### 양방향(Bidirectional) RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-review",
   "metadata": {},
   "source": [
    "마지막으로 살펴볼 것은 진행 방향에 변화를 준 RNN입니다. `날이 너무 [ ] 에어컨을 켰다` 라는 예문이 있다면, 빈칸에 들어갈 말이 '더워서'인 것은 어렵지 않게 유추할 수 있습니다. 그 근거는 아마도 `'에어컨을 켰다'` 는 말 때문이겠죠? 하지만 우리가 지금까지 배운 RNN은 모두 순방향이었기 때문에 에어컨이라는 정보가 없는 채로 빈칸에 들어갈 단어를 생성해야 합니다. 자칫하면 날이 너무 추워서 에어컨을 켰다 는 이상한 문장이 생성될지도 몰라요!\n",
    "\n",
    "이를 해결하기 위해 제안된 것이 양방향(Bidirectional) RNN입니다. 말이 조금 어렵지만, 그저 `진행 방향이 반대`인 `RNN을 2개` 겹쳐놓은 형태랍니다!\n",
    "\n",
    "원리만큼이나 간단하게 Tensorflow에서도 LSTM 등 모든 RNN 계열 레이어에 쉽게 적용시킬 수 있습니다. 사용하고자 하는 레이어를 `tf.keras.layers.Bidirectional()` 로 감싸주기만 하면 돼요!\n",
    "\n",
    "양방향(Bidirectional) RNN이 필요한 상황은 어떤 것일까요? 문장 분석이나 생성보다는 주로 기계번역 같은 테스크에 유리합니다. 사람도 대화를 하면서 듣고 이해하는 것은 순차적으로 들으면서 충분히 예측을 동원해서 잘 해냅니다. 그러나 문장을 번역하려면 일단은 번역해야 할 문장 전체를 끝까지 분석한 후 번역을 시도하는 것이 훨씬 유리합니다. 그래서 자연어처리를 계속하면서 알게 되겠지만, 번역기를 만들 때 양방향(Bidirectional) RNN 계열의 네트워크, 혹은 동일한 효과를 내는 Transformer 네트워크를 주로 사용하게 될 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sapphire-representation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 문장 데이터 형태: (1, 5, 100)\n",
      "Bidirectional RNN 결과 (최종 Step Output): (1, 5, 128)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "sentence = \"What time is it ?\"\n",
    "dic = {\n",
    "    \"is\": 0,\n",
    "    \"it\": 1,\n",
    "    \"What\": 2,\n",
    "    \"time\": 3,\n",
    "    \"?\": 4\n",
    "}\n",
    "\n",
    "sentence_tensor = tf.constant([[dic[word] for word in sentence.split()]])\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=len(dic), output_dim=100)\n",
    "emb_out = embedding_layer(sentence_tensor)\n",
    "\n",
    "print(\"입력 문장 데이터 형태:\", emb_out.shape)\n",
    "\n",
    "bi_rnn = \\\n",
    "tf.keras.layers.Bidirectional(\n",
    "    tf.keras.layers.SimpleRNN(units=64, use_bias=False, return_sequences=True)\n",
    ")\n",
    "bi_out = bi_rnn(emb_out)\n",
    "\n",
    "print(\"Bidirectional RNN 결과 (최종 Step Output):\", bi_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-advice",
   "metadata": {},
   "source": [
    "Bidirectional RNN은 순방향 Weight와 역방향 Weight를 각각 정의하므로 우리가 앞에서 배운 RNN의 2배 크기 Weight가 정의됩니다. units를 64로 정의해 줬고, 입력은 Embedding을 포함하여 (1, 5, 100), 그리고 양방향에 대한 Weight를 거쳐 나올 테니 출력은 (1, 5, 128) 이 맞죠?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
