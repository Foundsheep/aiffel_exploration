{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "demographic-disposition",
   "metadata": {},
   "source": [
    "## # 신경망 구성 (1) 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-inspiration",
   "metadata": {},
   "source": [
    "### 가장 흔한 예제인 MNIST 다시 보기\n",
    "> - 코드 몇 줄로 정확도 97%의 분류기를 만들 수 있다.  \n",
    "> - 또한 여기에는 이미지 분류에 특호된 Conv2D 레이어가 없고, 다층 퍼셉트론(Multi-Layer-Perceptron)으로만 이루어져 있다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "isolated-injury",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 39,760\n",
      "Trainable params: 39,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.8319 - accuracy: 0.8094\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2407 - accuracy: 0.9308\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1818 - accuracy: 0.9478\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1488 - accuracy: 0.9576\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1299 - accuracy: 0.9629\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1106 - accuracy: 0.9682\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1017 - accuracy: 0.9701\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0909 - accuracy: 0.9735\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0789 - accuracy: 0.9781\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0727 - accuracy: 0.9805\n",
      "313/313 - 0s - loss: 0.1040 - accuracy: 0.9700\n",
      "test_loss: 0.10400935262441635 \n",
      "test_accuracy: 0.9700000286102295\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MNIST 데이터를 로드. 다운로드하지 않았다면 다운로드까지 자동으로 진행됩니다. \n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()   \n",
    "\n",
    "# 모델에 맞게 데이터 가공\n",
    "x_train_norm, x_test_norm = x_train / 255.0, x_test / 255.0\n",
    "x_train_reshaped = x_train_norm.reshape(-1, x_train_norm.shape[1]*x_train_norm.shape[2])\n",
    "x_test_reshaped = x_test_norm.reshape(-1, x_test_norm.shape[1]*x_test_norm.shape[2])\n",
    "\n",
    "# 딥러닝 모델 구성 - 2 Layer Perceptron\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(50, activation='sigmoid', input_shape=(784,)))  # 입력층 d=784, 은닉층 레이어 H=50\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))   # 출력층 레이어 K=10\n",
    "model.summary()\n",
    "\n",
    "# 모델 구성과 학습\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train_reshaped, y_train, epochs=10)\n",
    "\n",
    "# 모델 테스트 결과\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-conclusion",
   "metadata": {},
   "source": [
    "### Numpy로 MLP 기반 딥러닝 모델 만들어 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "arranged-renewal",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(5, 784)\n"
     ]
    }
   ],
   "source": [
    "# 입력층 데이터의 모양(shape)\n",
    "print(x_train_reshaped.shape)\n",
    "\n",
    "# 테스트를 위해 x_train_reshaped의 앞 5개의 데이터를 가져온다.\n",
    "X = x_train_reshaped[:5]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "marine-parcel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 50)\n",
      "(50,)\n",
      "(5, 50)\n"
     ]
    }
   ],
   "source": [
    "weight_init_std = 0.1\n",
    "input_size = 784\n",
    "hidden_size=50\n",
    "\n",
    "# 인접 레이어간 관계를 나타내는 파라미터 W를 생성하고 random 초기화\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)  \n",
    "# 바이어스 파라미터 b를 생성하고 Zero로 초기화\n",
    "b1 = np.zeros(hidden_size)\n",
    "\n",
    "a1 = np.dot(X, W1) + b1   # 은닉층 출력\n",
    "\n",
    "print(W1.shape)\n",
    "print(b1.shape)\n",
    "print(a1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unique-grade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.34081808e-01,  9.99764838e-02,  1.59883946e-01, -9.38411416e-01,\n",
       "        6.19344797e-01, -6.30136947e-01,  2.32132003e-01,  4.28541523e-01,\n",
       "       -8.72904863e-02, -5.64708936e-01,  4.69065918e-01,  2.18260695e-01,\n",
       "       -6.77655913e-01, -2.75638857e-01, -1.38632387e+00,  1.34360561e-03,\n",
       "       -3.79925354e-01, -1.13151679e+00,  2.04966645e-01,  1.07083987e+00,\n",
       "        1.56769115e-01,  8.67232815e-02,  1.20294007e+00,  8.45160883e-01,\n",
       "        1.11978838e+00,  1.29101209e-01, -2.36026028e-01,  6.35916295e-01,\n",
       "       -1.65547260e+00, -2.70296599e+00, -5.19223850e-01,  2.01331761e+00,\n",
       "       -1.77342429e-01,  1.45411159e-01,  1.23637573e+00,  8.89331580e-01,\n",
       "       -9.60317711e-01, -6.05859102e-01, -1.99299936e+00, -1.74075996e+00,\n",
       "        8.29763153e-02,  3.23347154e-02,  6.76493426e-01, -4.71212577e-01,\n",
       "       -2.03138585e-01, -1.04579231e+00, -5.22504251e-03,  7.56942242e-01,\n",
       "        6.96339525e-02,  2.11337392e-01])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 번째 데이터의 은닉층 출력을 확인해 봅시다.  50dim의 벡터가 나오나요?\n",
    "a1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-sociology",
   "metadata": {},
   "source": [
    "## # 신경망 구성 (2) 활성화 함수와 손실 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-metabolism",
   "metadata": {},
   "source": [
    "> 위에서 은닉층으로 오는 input에 sigmoid 함수 쓰기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-drama",
   "metadata": {},
   "source": [
    "### # 활성화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "nutritional-president",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65341442 0.52497332 0.53988606 0.28122134 0.65006952 0.34747949\n",
      " 0.5577738  0.60552534 0.47819122 0.3624586  0.61516265 0.55434959\n",
      " 0.33678468 0.43152329 0.19999528 0.5003359  0.4061449  0.24388129\n",
      " 0.55106302 0.7447566  0.53911221 0.52166724 0.76904739 0.69955104\n",
      " 0.75394946 0.53223055 0.4412659  0.65382975 0.16037068 0.06279857\n",
      " 0.37303374 0.88218827 0.45578023 0.53628887 0.77493253 0.70875221\n",
      " 0.27681459 0.35300437 0.11993991 0.14921643 0.52073218 0.50808297\n",
      " 0.66295562 0.38432928 0.44938927 0.26003391 0.49869374 0.68068949\n",
      " 0.51740146 0.55263858]\n"
     ]
    }
   ],
   "source": [
    "# 위 수식의 sigmoid 함수를 구현해 봅니다.\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))  \n",
    "\n",
    "\n",
    "z1 = sigmoid(a1)\n",
    "print(z1[0])  # sigmoid의 출력은 모든 element가 0에서 1사이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "expressed-remains",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go~\n"
     ]
    }
   ],
   "source": [
    "# 그리고 Dense 레이어가 나오는데, 이것을 구현함\n",
    "# 단일 레이어 구현 함수\n",
    "def affine_layer_forward(X, W, b):\n",
    "    y = np.dot(X, W) + b\n",
    "    cache = (X, W, b)\n",
    "    return y, cache\n",
    "\n",
    "print('go~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "scientific-wonder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.86076203 -0.25466564  0.0982923  -0.31694162  0.28814521 -0.15172322\n",
      "  0.28185494  0.24985275  0.58670591  0.04540416]\n"
     ]
    }
   ],
   "source": [
    "# 윗 함수 다시 구현\n",
    "# 입력 -> 은닉 -> 출력의 활성화 함수 전까지\n",
    "input_size = 784\n",
    "hidden_size = 50\n",
    "output_size = 10\n",
    "\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "z1 = sigmoid(a1)\n",
    "a2, cache2 = affine_layer_forward(z1, W2, b2)    # z1이 다시 두번째 레이어의 입력이 됩니다. \n",
    "\n",
    "print(a2[0])  # 최종 출력이 output_size만큼의 벡터가 되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "detailed-castle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "literary-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력 전에 활성화 함수로 softmax 줘보기\n",
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0) # DJ 추가 # 여기서는 각 데이터마다 갖는 feature 값 중 최대를 빼는데 그럼 음수도 생김\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0) # DJ 추가 # 그러나 exp()에 음수들 어가도 되서 괜찮고\n",
    "                                                  # 여기서는 데이터를 구분하는 축에 따라 sum()한 값이 결국 '/' 할 때는 브로드캐스팅 됨\n",
    "        return y.T \n",
    "\n",
    "    x = x - np.max(x) # 오버플로 대책\n",
    "    return np.exp(x) / np.sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "appreciated-victory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03960368, 0.07260388, 0.10333501, 0.06822031, 0.12493945,\n",
       "       0.08047614, 0.12415601, 0.12024565, 0.16840805, 0.09801183])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = softmax(a2)\n",
    "y_hat[0]  # 10개의 숫자 중 하나일 확률이 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-robinson",
   "metadata": {},
   "source": [
    "### # 손실함수 (Loss Functions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "usual-expression",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 우선 정답이 맞는지 라벨을 통해 확인해보기\n",
    "# 정답 라벨을 One-hot 인코딩하는 함수\n",
    "def _change_one_hot_label(X, num_category):\n",
    "    T = np.zeros((X.size, num_category))\n",
    "    for idx, row in enumerate(T):\n",
    "        row[X[idx]] = 1 # DJ 추가 # 맨 처음 데이터수 x 카테고리 수 shape의 0행렬을 만든다.\n",
    "                        # 그리고 결국 정답 integer를 0행렬 각 row의 인덱스로 넣으면서 그 자리에 1을 할당하는 것\n",
    "    return T\n",
    "\n",
    "Y_digit = y_train[:5]\n",
    "t = _change_one_hot_label(Y_digit, 10)\n",
    "t     # 정답 라벨의 One-hot 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-enemy",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "committed-metro",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "wound-buddy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "iraqi-quebec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_digit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "pointed-mercury",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_digit.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "moved-moses",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((5, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adjusted-graphic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "2 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "4 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i, v in enumerate(np.zeros((5, 10))):\n",
    "    print(i, v)\n",
    "    count += 1\n",
    "    if count == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "august-maker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9], dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "retained-peter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_digit[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-custody",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-internship",
   "metadata": {},
   "source": [
    "#### continued.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "angry-hacker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03960368 0.07260388 0.10333501 0.06822031 0.12493945 0.08047614\n",
      " 0.12415601 0.12024565 0.16840805 0.09801183]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# 실제 값과 확인\n",
    "print(y_hat[0])\n",
    "print(t[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-probe",
   "metadata": {},
   "source": [
    "> 아직 확률이 정확하지 않음..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "balanced-lover",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.593189765081021"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 손실 함수 넣기\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t])) / batch_size\n",
    "                         # 이 바로 윗 부분이 잘 이해 안 갔는데, integer array indexing이다.\n",
    "                         # 전체 데이터 갯수에서 t, 즉 제일 확률이 높은 열 인덱스 값을 가져온다.\n",
    "                         # batch_size로 나눠주는 건 데이터마다의 손실함수 값을 주\n",
    "\n",
    "Loss = cross_entropy_error(y_hat, t)\n",
    "Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-china",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "prime-pepper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "going-tenant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "spare-dealing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03960368, 0.07260388, 0.10333501, 0.06822031, 0.12493945,\n",
       "        0.08047614, 0.12415601, 0.12024565, 0.16840805, 0.09801183],\n",
       "       [0.03903497, 0.05991991, 0.10358   , 0.08502322, 0.11789689,\n",
       "        0.08193655, 0.12466677, 0.14342779, 0.13848516, 0.10602875],\n",
       "       [0.04127167, 0.06946645, 0.08952505, 0.06370002, 0.11141347,\n",
       "        0.09038227, 0.12690006, 0.14521688, 0.14937674, 0.1127474 ],\n",
       "       [0.04435092, 0.06721695, 0.10522656, 0.07203785, 0.10506611,\n",
       "        0.07721062, 0.13533711, 0.14410762, 0.16149253, 0.08795374],\n",
       "       [0.04063413, 0.07758915, 0.09443401, 0.1038031 , 0.11279805,\n",
       "        0.07368765, 0.1274409 , 0.10829237, 0.16191237, 0.09940828]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "naughty-prefix",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 10)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "classified-discretion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08047614, 0.03903497, 0.11141347, 0.06721695, 0.09940828])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat[np.arange(5), t.argmax(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "french-affiliation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.51979453, -3.24329747, -2.19450707, -2.6998299 , -2.30851986])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(y_hat[np.arange(5), t.argmax(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "sought-piano",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-12.965948825405105"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.log(y_hat[np.arange(5), t.argmax(axis=1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "artistic-auction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.593189765081021"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.sum(np.log(y_hat[np.arange(5), t.argmax(axis=1)])) / 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-tracy",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-diabetes",
   "metadata": {},
   "source": [
    "### # Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "documentary-kidney",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00792074,  0.01452078,  0.020667  ,  0.01364406,  0.02498789,\n",
       "        -0.18390477,  0.0248312 ,  0.02404913,  0.03368161,  0.01960237],\n",
       "       [-0.19219301,  0.01198398,  0.020716  ,  0.01700464,  0.02357938,\n",
       "         0.01638731,  0.02493335,  0.02868556,  0.02769703,  0.02120575],\n",
       "       [ 0.00825433,  0.01389329,  0.01790501,  0.01274   , -0.17771731,\n",
       "         0.01807645,  0.02538001,  0.02904338,  0.02987535,  0.02254948],\n",
       "       [ 0.00887018, -0.18655661,  0.02104531,  0.01440757,  0.02101322,\n",
       "         0.01544212,  0.02706742,  0.02882152,  0.03229851,  0.01759075],\n",
       "       [ 0.00812683,  0.01551783,  0.0188868 ,  0.02076062,  0.02255961,\n",
       "         0.01473753,  0.02548818,  0.02165847,  0.03238247, -0.18011834]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy로 Gradient Descent 구현하기\n",
    "batch_num = y_hat.shape[0]\n",
    "dy = (y_hat - t) / batch_num\n",
    "dy    # softmax값의 출력으로 Loss를 미분한 값\n",
    "\n",
    "# y 가 one-hot encoded vector이고 크로스엔트로피를 손실함수로 갖고 softmax 함수가 중간에 있을 때\n",
    "# 위와 같은 도함수가 나오는걸 증명한 링크\n",
    "# https://deepnotes.io/softmax-crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-mechanics",
   "metadata": {},
   "source": [
    "> 여기서 dy란 $\\frac{\\partial Loss}{\\partial y}$  \n",
    "> dy를 구하면 다른 건 chain rule 로 구할 수 있다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "floral-laundry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.10296166, -0.09027263,  0.06792929,  0.05247001, -0.05379362,\n",
       "        -0.11764271,  0.08693793,  0.09027262,  0.10668978, -0.03962901],\n",
       "       [-0.06746099, -0.09837717,  0.04451733,  0.03482952,  0.00391231,\n",
       "        -0.06177022,  0.0567224 ,  0.05833033,  0.06949585, -0.04019938],\n",
       "       [-0.11949504, -0.06373423,  0.06266159,  0.04988737, -0.05499871,\n",
       "        -0.07425048,  0.08050852,  0.08360286,  0.09809712, -0.062279  ],\n",
       "       [-0.02845243, -0.05266473,  0.03484133,  0.02655173, -0.09043075,\n",
       "        -0.0272896 ,  0.0457762 ,  0.04850376,  0.0555439 , -0.01237941],\n",
       "       [-0.13283476, -0.07968699,  0.06097088,  0.04829713,  0.01258809,\n",
       "        -0.10372111,  0.07711427,  0.07934942,  0.09451258, -0.05658951],\n",
       "       [-0.0639509 , -0.03451187,  0.03481476,  0.02779659, -0.0269664 ,\n",
       "        -0.04468536,  0.04470012,  0.04622336,  0.05459993, -0.03802022],\n",
       "       [-0.0908246 , -0.09010187,  0.06059081,  0.04636508, -0.04638948,\n",
       "        -0.10762128,  0.07744818,  0.08064383,  0.09501103, -0.02512171],\n",
       "       [-0.05159322, -0.10882563,  0.05524877,  0.04279466, -0.0830277 ,\n",
       "        -0.04833691,  0.07189959,  0.0750531 ,  0.08758242, -0.04079506],\n",
       "       [-0.15328432, -0.13696945,  0.07138104,  0.05662873,  0.00850085,\n",
       "        -0.07509563,  0.09076417,  0.09401069,  0.11029169, -0.06622777],\n",
       "       [-0.09389793, -0.05723159,  0.05494466,  0.04324624, -0.08877288,\n",
       "        -0.04930825,  0.07122081,  0.07478959,  0.08636549, -0.04135612],\n",
       "       [-0.14051197, -0.03616202,  0.05365667,  0.04199668, -0.01720675,\n",
       "        -0.09730372,  0.06780692,  0.07085737,  0.08271952, -0.02585271],\n",
       "       [-0.08933368, -0.03207819,  0.04673965,  0.03912434, -0.04516597,\n",
       "        -0.02367479,  0.0606542 ,  0.06215484,  0.07369507, -0.09211547],\n",
       "       [-0.03955967, -0.07096325,  0.04745596,  0.03903865, -0.05380666,\n",
       "        -0.0285051 ,  0.06207278,  0.06308946,  0.07601079, -0.09483297],\n",
       "       [-0.12583054, -0.12489629,  0.06821276,  0.05419526,  0.01727077,\n",
       "        -0.09554165,  0.0866703 ,  0.08885867,  0.10614093, -0.0750802 ],\n",
       "       [-0.09991731,  0.00968892,  0.04875696,  0.04008739, -0.01844691,\n",
       "        -0.09996706,  0.06215047,  0.06292479,  0.07690683, -0.08218408],\n",
       "       [-0.10689448, -0.1230244 ,  0.06853724,  0.05451353, -0.06969417,\n",
       "        -0.03953729,  0.08874818,  0.0924045 ,  0.10753573, -0.07258885],\n",
       "       [-0.1050144 , -0.04775246,  0.04649953,  0.03828669, -0.00884714,\n",
       "        -0.04183746,  0.05951224,  0.06105165,  0.07240875, -0.07430739],\n",
       "       [-0.0213218 , -0.01982786,  0.03271908,  0.02720331, -0.04243797,\n",
       "        -0.03982155,  0.04280261,  0.04297045,  0.05297903, -0.07526532],\n",
       "       [-0.10575976, -0.05981328,  0.05190682,  0.03932923, -0.06103963,\n",
       "        -0.08303249,  0.06630725,  0.07026204,  0.08062397,  0.00121585],\n",
       "       [-0.10854977, -0.08483551,  0.05642899,  0.04575894, -0.07562258,\n",
       "        -0.00121414,  0.0734508 ,  0.07693824,  0.08823424, -0.07058921],\n",
       "       [-0.13013372, -0.04802339,  0.05904299,  0.04549382, -0.0578056 ,\n",
       "        -0.09946512,  0.07526486,  0.07922267,  0.09170724, -0.01530375],\n",
       "       [-0.06443832, -0.10532845,  0.04798378,  0.03797658, -0.07869723,\n",
       "         0.00350041,  0.0628075 ,  0.06610524,  0.07546412, -0.04537362],\n",
       "       [-0.04943377, -0.04147894,  0.03606141,  0.02957597, -0.04208277,\n",
       "        -0.02244528,  0.04695644,  0.04817768,  0.05723307, -0.06256382],\n",
       "       [-0.02999594, -0.12748593,  0.03317456,  0.02522903, -0.02921328,\n",
       "         0.00155849,  0.04312226,  0.04549047,  0.0518289 , -0.01370855],\n",
       "       [-0.01246592, -0.06073434,  0.03590054,  0.02592846, -0.09358093,\n",
       "        -0.06404863,  0.04683535,  0.04979   ,  0.05745879,  0.01491667],\n",
       "       [-0.09954176, -0.04697434,  0.05745608,  0.04548169, -0.04791786,\n",
       "        -0.09279251,  0.07365689,  0.0760943 ,  0.09034842, -0.05581092],\n",
       "       [-0.08487868, -0.03436001,  0.03409618,  0.02811079, -0.04112841,\n",
       "         0.00198234,  0.04421929,  0.04637333,  0.05292643, -0.04734128],\n",
       "       [-0.10535051, -0.06624618,  0.05872641,  0.04709717, -0.07718893,\n",
       "        -0.03947116,  0.07611287,  0.0793925 ,  0.09221216, -0.06528432],\n",
       "       [-0.12171873, -0.0568083 ,  0.05080586,  0.03837328, -0.08059934,\n",
       "        -0.0578184 ,  0.06511625,  0.07002312,  0.0783521 ,  0.01427418],\n",
       "       [-0.12914939, -0.07780289,  0.07246856,  0.05697755, -0.05852826,\n",
       "        -0.10767383,  0.09285741,  0.09637717,  0.11356204, -0.05908837],\n",
       "       [-0.10029082, -0.04973329,  0.06449849,  0.05130597, -0.07312701,\n",
       "        -0.09300548,  0.08315636,  0.0858941 ,  0.10192695, -0.07062526],\n",
       "       [-0.02192752, -0.07797054,  0.0390573 ,  0.02936571, -0.04328597,\n",
       "        -0.07423383,  0.05034315,  0.05213401,  0.06218684, -0.01566915],\n",
       "       [-0.14940034, -0.08368585,  0.08019003,  0.0636588 , -0.04715317,\n",
       "        -0.11782037,  0.10258848,  0.10599203,  0.12554448, -0.0799141 ],\n",
       "       [-0.05668896, -0.01733595,  0.03987947,  0.03374161,  0.00608155,\n",
       "        -0.06910169,  0.05111097,  0.05050935,  0.06359852, -0.10179487],\n",
       "       [-0.04465843, -0.0450737 ,  0.04030375,  0.03233323,  0.00367333,\n",
       "        -0.08934384,  0.05138122,  0.05148965,  0.06407963, -0.06418484],\n",
       "       [-0.1189925 , -0.05383857,  0.06375936,  0.04955409, -0.03600479,\n",
       "        -0.13031745,  0.08108586,  0.08398732,  0.09974698, -0.0389803 ],\n",
       "       [-0.10888708, -0.0649671 ,  0.04728159,  0.03849303, -0.0393679 ,\n",
       "        -0.01146906,  0.06101975,  0.06374531,  0.07337147, -0.05922   ],\n",
       "       [-0.07619046, -0.08613587,  0.05650359,  0.04316282, -0.05199993,\n",
       "        -0.09830781,  0.07241851,  0.07541956,  0.08886915, -0.02373956],\n",
       "       [-0.07208163, -0.07449077,  0.03798105,  0.02959389, -0.02338997,\n",
       "        -0.03402384,  0.0486767 ,  0.05101769,  0.05894792, -0.02223105],\n",
       "       [-0.06031553, -0.06033908,  0.05736992,  0.04389994, -0.08785932,\n",
       "        -0.10598343,  0.07407088,  0.07708008,  0.0911818 , -0.02910526],\n",
       "       [-0.02557755, -0.05504153,  0.04338805,  0.03423209, -0.10054771,\n",
       "        -0.03343294,  0.05716015,  0.05941867,  0.06979862, -0.04939784],\n",
       "       [-0.07818308, -0.03043601,  0.04002109,  0.03350274,  0.01129793,\n",
       "        -0.05624853,  0.05105725,  0.05124109,  0.06289843, -0.08515093],\n",
       "       [-0.02048465, -0.06360857,  0.03993697,  0.03135084, -0.06567938,\n",
       "        -0.04551289,  0.05219567,  0.05377837,  0.06411953, -0.04609589],\n",
       "       [-0.01685742, -0.09113981,  0.03335376,  0.02640498, -0.00086955,\n",
       "        -0.04070974,  0.04299243,  0.04344398,  0.05307177, -0.0496904 ],\n",
       "       [-0.0713341 , -0.07090408,  0.06530711,  0.05214153, -0.02695073,\n",
       "        -0.1267551 ,  0.08374909,  0.08474186,  0.10391944, -0.09391502],\n",
       "       [-0.05256116, -0.07617333,  0.04861594,  0.03892186, -0.03860148,\n",
       "        -0.05566488,  0.06289163,  0.06432518,  0.07719298, -0.06894673],\n",
       "       [-0.06724024, -0.07059332,  0.04589194,  0.03827077, -0.04932878,\n",
       "         0.00149153,  0.06000572,  0.06158401,  0.07261055, -0.09269219],\n",
       "       [-0.09841321, -0.05739978,  0.05880785,  0.04462222, -0.07035658,\n",
       "        -0.11450548,  0.07520808,  0.07894714,  0.09218012, -0.00909036],\n",
       "       [-0.03056667, -0.01335102,  0.03241063,  0.02443269, -0.0226279 ,\n",
       "        -0.1111672 ,  0.04110191,  0.04192263,  0.05171729, -0.01387236],\n",
       "       [-0.02360973, -0.0620584 ,  0.04600968,  0.03637669, -0.03685395,\n",
       "        -0.08808121,  0.05944205,  0.0600995 ,  0.07394604, -0.06527067]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dW2 = np.dot(z1.T, dy)    \n",
    "dW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "alternate-portuguese",
   "metadata": {},
   "outputs": [],
   "source": [
    "dW2 = np.dot(z1.T, dy)\n",
    "db2 = np.sum(dy, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "together-booking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중간에 sigmoid도 한 번 사용됐으니\n",
    "# 이에 대한 gradient도 구해야 함\n",
    "def sigmoid_grad(x):\n",
    "    return (1.0 - sigmoid(x)) * sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "resident-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz1 = np.dot(dy, W2.T)\n",
    "da1 = sigmoid_grad(a1) * dz1\n",
    "dW1 = np.dot(X.T, da1)\n",
    "db1 = np.sum(dz1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "continuing-premium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate도 고려한\n",
    "# 파라미터 업데이트 함수\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate):\n",
    "    W1 = W1 - learning_rate*dW1\n",
    "    b1 = b1 - learning_rate*db1\n",
    "    W2 = W2 - learning_rate*dW2\n",
    "    b2 = b2 - learning_rate*db2\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-protection",
   "metadata": {},
   "source": [
    "### # Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aggregate-property",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 역전파를 통해 미분 계수 구하는 함수\n",
    "def affine_layer_backward(dy, cache):\n",
    "    X, W, b = cache\n",
    "    dX = np.dot(dy, W.T)\n",
    "    dW = np.dot(X.T, dy)\n",
    "    db = np.sum(dy, axis=0)\n",
    "    return dX, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "premium-decade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.07024955 0.09734939 0.09060088 0.12063172 0.11840632 0.0768448\n",
      "  0.10088194 0.07672158 0.12693046 0.12138337]\n",
      " [0.08362928 0.08721015 0.07151939 0.12208646 0.12634531 0.0868721\n",
      "  0.0960289  0.08992881 0.12125131 0.11512829]\n",
      " [0.08540055 0.0896849  0.06768838 0.09804973 0.13539394 0.08723975\n",
      "  0.11450589 0.07778957 0.11674581 0.12750148]\n",
      " [0.07959859 0.08521269 0.07833179 0.11815262 0.14388454 0.07651292\n",
      "  0.10215738 0.09280785 0.11506022 0.10828139]\n",
      " [0.08208761 0.08450531 0.07438452 0.10736445 0.15643022 0.06968551\n",
      "  0.09872937 0.09272951 0.10886535 0.12521816]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  2.3174396970653164\n"
     ]
    }
   ],
   "source": [
    "# 이로서 순전파, 역전파를 통해\n",
    "# 파라미터가 업데이틑 과정을 아래의 코드로 구현함\n",
    "\n",
    "# 파라미터 초기화\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "# Forward Propagation\n",
    "a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "z1 = sigmoid(a1)\n",
    "a2, cache2 = affine_layer_forward(z1, W2, b2)\n",
    "\n",
    "# 추론과 오차(Loss) 계산\n",
    "y_hat = softmax(a2)\n",
    "t = _change_one_hot_label(Y_digit, 10)   # 정답 One-hot 인코딩\n",
    "Loss = cross_entropy_error(y_hat, t)\n",
    "\n",
    "print(y_hat)\n",
    "print(t)\n",
    "print('Loss: ', Loss)\n",
    "        \n",
    "dy = (y_hat - t) / X.shape[0]\n",
    "dz1, dW2, db2 = affine_layer_backward(dy, cache2)\n",
    "da1 = sigmoid_grad(a1) * dz1\n",
    "dX, dW1, db1 = affine_layer_backward(da1, cache1)\n",
    "\n",
    "# 경사하강법을 통한 파라미터 업데이트    \n",
    "learning_rate = 0.1\n",
    "W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-sharp",
   "metadata": {},
   "source": [
    "> 실험해봤는데 위에서 initialising 하는 부분 빼고 코드를 반복해서 실행하면  \n",
    "> Loss가 줄어드는 것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-engineering",
   "metadata": {},
   "source": [
    "## # 모델 학습 step-by-step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-superintendent",
   "metadata": {},
   "source": [
    "- 모델이 학습해가는 과정을 5번 반복해서 실제 loss가 줄어드는지 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "linear-helmet",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "def train_step(X, Y, W1, b1, W2, b2, learning_rate=0.1, verbose=False):\n",
    "    a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "    z1 = sigmoid(a1)\n",
    "    a2, cache2 = affine_layer_forward(z1, W2, b2)\n",
    "    y_hat = softmax(a2)\n",
    "    t = _change_one_hot_label(Y, 10)\n",
    "    Loss = cross_entropy_error(y_hat, t)\n",
    "\n",
    "    if verbose:\n",
    "        print('---------')\n",
    "        print(y_hat)\n",
    "        print(t)\n",
    "        print('Loss: ', Loss)\n",
    "        \n",
    "    dy = (y_hat - t) / X.shape[0]\n",
    "    dz1, dW2, db2 = affine_layer_backward(dy, cache2)\n",
    "    da1 = sigmoid_grad(a1) * dz1\n",
    "    dX, dW1, db1 = affine_layer_backward(da1, cache1)\n",
    "    \n",
    "    W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)\n",
    "    \n",
    "    return W1, b1, W2, b2, Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "announced-tower",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "[[0.08527203 0.07994717 0.11869815 0.07021829 0.15548542 0.09905219\n",
      "  0.06070831 0.14202441 0.14137745 0.04721659]\n",
      " [0.0901562  0.07235708 0.13928587 0.08624665 0.12868083 0.09120542\n",
      "  0.06758216 0.13218067 0.14475491 0.04755021]\n",
      " [0.08385518 0.06449953 0.14237863 0.07363839 0.15245708 0.0974574\n",
      "  0.08162625 0.13433735 0.11189395 0.05785625]\n",
      " [0.07793474 0.06331486 0.10024005 0.08217073 0.1498699  0.11936635\n",
      "  0.05531203 0.15148173 0.15391335 0.04639626]\n",
      " [0.10217162 0.06915798 0.13440687 0.06378825 0.14859312 0.10664448\n",
      "  0.06909434 0.15190328 0.10998032 0.04425975]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  2.4953013915468074\n",
      "---------\n",
      "[[0.10192466 0.09991016 0.09935188 0.06373496 0.16502791 0.12299631\n",
      "  0.05572437 0.11620344 0.11595397 0.05917235]\n",
      " [0.11338249 0.08918706 0.11850394 0.07939999 0.13934392 0.10799408\n",
      "  0.06251548 0.10978769 0.12056185 0.05932351]\n",
      " [0.09813393 0.07890455 0.11987277 0.0671912  0.17286889 0.11125072\n",
      "  0.07537729 0.11117024 0.09320766 0.07202275]\n",
      " [0.09280539 0.0833987  0.08359013 0.07444906 0.16219365 0.14217987\n",
      "  0.05098362 0.12409075 0.12694193 0.05936692]\n",
      " [0.11990912 0.08568279 0.11299809 0.05840735 0.16090466 0.12382122\n",
      "  0.06374133 0.12502488 0.0916751  0.05783546]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  2.272417396030093\n",
      "---------\n",
      "[[0.11540866 0.11831523 0.08370511 0.05690083 0.16756365 0.14448556\n",
      "  0.0502267  0.09645883 0.09623822 0.0706972 ]\n",
      " [0.13524526 0.1043546  0.10137567 0.071904   0.14462648 0.12127905\n",
      "  0.05679532 0.09232022 0.10142771 0.07067169]\n",
      " [0.10957921 0.09215487 0.10165047 0.06050549 0.1885779  0.12106745\n",
      "  0.06857388 0.09328558 0.07850736 0.08609779]\n",
      " [0.10455926 0.10386113 0.07014499 0.06635068 0.16763849 0.16001294\n",
      "  0.04609795 0.1031142  0.10593503 0.07228533]\n",
      " [0.13391303 0.10096529 0.09592076 0.05276115 0.16743692 0.13671024\n",
      "  0.05792191 0.10463264 0.07746086 0.0722772 ]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  2.099086458581829\n",
      "---------\n",
      "[[0.12582404 0.13455367 0.07121068 0.05050513 0.16596201 0.16334178\n",
      "  0.04494542 0.08120329 0.08091216 0.08154182]\n",
      " [0.15539555 0.11738075 0.08743527 0.06468751 0.14648136 0.13127271\n",
      "  0.05118965 0.07854941 0.08624645 0.08136134]\n",
      " [0.11829899 0.10383345 0.08701873 0.0542446  0.20119825 0.12738681\n",
      "  0.0620177  0.07932045 0.06689413 0.09978689]\n",
      " [0.11328975 0.1239429  0.05942728 0.05879559 0.16880138 0.17314038\n",
      "  0.04134442 0.08690955 0.08954956 0.08479919]\n",
      " [0.14443365 0.1145353  0.08236203 0.04745547 0.17045416 0.14578821\n",
      "  0.05234268 0.08892137 0.06634078 0.08736635]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  1.9605471861334198\n",
      "---------\n",
      "[[0.13360201 0.14833185 0.06123404 0.044832   0.16224998 0.17988901\n",
      "  0.0401772  0.06927089 0.06889967 0.09151334]\n",
      " [0.17387642 0.12806223 0.07609902 0.05813155 0.14637437 0.1385291\n",
      "  0.04603567 0.06756972 0.0741091  0.09121283]\n",
      " [0.12464342 0.11371189 0.07523806 0.04864425 0.21208704 0.13092365\n",
      "  0.0560375  0.06827025 0.05763284 0.11281109]\n",
      " [0.11941384 0.14309481 0.05087822 0.05210394 0.16761421 0.18237385\n",
      "  0.03701163 0.07423904 0.07665977 0.09661068]\n",
      " [0.15199178 0.12613322 0.07152659 0.04270034 0.1715695  0.15180135\n",
      "  0.04727652 0.07660707 0.05752798 0.10286566]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  1.846832705811823\n"
     ]
    }
   ],
   "source": [
    "X = x_train_reshaped[:5]\n",
    "Y = y_train[:5]\n",
    "\n",
    "# train_step을 다섯 번 반복 돌립니다.\n",
    "for i in range(5):\n",
    "    W1, b1, W2, b2, _ = train_step(X, Y, W1, b1, W2, b2, learning_rate=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-grove",
   "metadata": {},
   "source": [
    "## # 추론 과정 구현과 정확도(Accuracy) 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "agricultural-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측값 주는 함수 만들기\n",
    "def predict(W1, b1, W2, b2, X):\n",
    "    a1 = np.dot(X, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    y = softmax(a2)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "thermal-mississippi",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1392747 , 0.15961685, 0.05322276, 0.03992553, 0.15764413,\n",
       "       0.19465683, 0.03599955, 0.05981824, 0.05938411, 0.1004573 ])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = x_train[:100] 에 대해 모델 추론을 시도합니다. \n",
    "X = x_train_reshaped[:100]\n",
    "Y = y_test[:100]\n",
    "result = predict(W1, b1, W2, b2, X)\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "industrial-patrick",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(W1, b1, W2, b2, x, y):\n",
    "    y_hat = predict(W1, b1, W2, b2, x) # 예측된 카테고리별 확률값\n",
    "    y_hat = np.argmax(y_hat, axis=1)   # 그 확률값 중 제일 높은 걸 라벨 정수로 반환\n",
    "\n",
    "    accuracy = np.sum(y_hat == y) / float(x.shape[0])  # 맞은 갯수만큼 다 더하고 전체 갯수로 나눈다.\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "czech-teach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1392747  0.15961685 0.05322276 0.03992553 0.15764413 0.19465683\n",
      " 0.03599955 0.05981824 0.05938411 0.1004573 ]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "0.11\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy(W1, b1, W2, b2, X, Y)\n",
    "\n",
    "t = _change_one_hot_label(Y, 10)\n",
    "print(result[0])\n",
    "print(t[0])\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-location",
   "metadata": {},
   "source": [
    "> 5번의 학습으로는 아직 11%의 정확도임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-france",
   "metadata": {},
   "source": [
    "## # 전체 학습 사이클 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dangerous-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 초기화 함수\n",
    "def init_params(input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "\n",
    "    W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "    b1 = np.zeros(hidden_size)\n",
    "    W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "    b2 = np.zeros(output_size)\n",
    "\n",
    "    print(W1.shape)\n",
    "    print(b1.shape)\n",
    "    print(W2.shape)\n",
    "    print(b2.shape)\n",
    "    \n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-grace",
   "metadata": {},
   "source": [
    "> 아래의 코드는 GPU를 사용하는 게 아니어서 오래 걸림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "apart-lincoln",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 50)\n",
      "(50,)\n",
      "(50, 10)\n",
      "(10,)\n",
      "Loss:  2.300419832301038\n",
      "train acc, test acc | 0.11236666666666667, 0.1135\n",
      "Loss:  0.8619931104840401\n",
      "train acc, test acc | 0.7841833333333333, 0.7902\n",
      "Loss:  0.6244740794365812\n",
      "train acc, test acc | 0.8769333333333333, 0.8831\n",
      "Loss:  0.3061103958236115\n",
      "train acc, test acc | 0.8997833333333334, 0.9024\n",
      "Loss:  0.45359572322850705\n",
      "train acc, test acc | 0.9072, 0.9115\n",
      "Loss:  0.29885723332490416\n",
      "train acc, test acc | 0.9141833333333333, 0.9179\n",
      "Loss:  0.1926438164189583\n",
      "train acc, test acc | 0.9186833333333333, 0.9215\n",
      "Loss:  0.25909351867185315\n",
      "train acc, test acc | 0.9240833333333334, 0.9254\n",
      "Loss:  0.18691661079180688\n",
      "train acc, test acc | 0.9274666666666667, 0.9289\n",
      "Loss:  0.3719530897305575\n",
      "train acc, test acc | 0.9304166666666667, 0.9333\n",
      "Loss:  0.24926630635498248\n",
      "train acc, test acc | 0.9335666666666667, 0.9361\n",
      "Loss:  0.09826880750504101\n",
      "train acc, test acc | 0.9357666666666666, 0.9385\n",
      "Loss:  0.16780735238824762\n",
      "train acc, test acc | 0.9386333333333333, 0.9399\n",
      "Loss:  0.1921597435118945\n",
      "train acc, test acc | 0.9414333333333333, 0.9418\n",
      "Loss:  0.23117205506069333\n",
      "train acc, test acc | 0.9428666666666666, 0.9431\n",
      "Loss:  0.19465231200612002\n",
      "train acc, test acc | 0.94435, 0.9451\n",
      "Loss:  0.11791843310535134\n",
      "train acc, test acc | 0.946, 0.9458\n",
      "Loss:  0.16635012137859678\n",
      "train acc, test acc | 0.9479, 0.9466\n",
      "Loss:  0.16041400065248168\n",
      "train acc, test acc | 0.9493666666666667, 0.9486\n",
      "Loss:  0.12981209315228115\n",
      "train acc, test acc | 0.9510666666666666, 0.9486\n",
      "Loss:  0.14233603452928867\n",
      "train acc, test acc | 0.9524, 0.9497\n",
      "Loss:  0.20134555629484369\n",
      "train acc, test acc | 0.9536666666666667, 0.9509\n",
      "Loss:  0.07475115439184316\n",
      "train acc, test acc | 0.9545333333333333, 0.9507\n",
      "Loss:  0.15362920184939716\n",
      "train acc, test acc | 0.9554166666666667, 0.9522\n",
      "Loss:  0.15253073366616285\n",
      "train acc, test acc | 0.9567666666666667, 0.9534\n",
      "Loss:  0.1489041374293235\n",
      "train acc, test acc | 0.9576, 0.9536\n",
      "Loss:  0.1678254018067146\n",
      "train acc, test acc | 0.9585333333333333, 0.9557\n",
      "Loss:  0.14960002002678296\n",
      "train acc, test acc | 0.9594666666666667, 0.9556\n",
      "Loss:  0.19424049366054494\n",
      "train acc, test acc | 0.9606166666666667, 0.9562\n",
      "Loss:  0.11761300620178904\n",
      "train acc, test acc | 0.9610833333333333, 0.9572\n",
      "Loss:  0.12674322012412623\n",
      "train acc, test acc | 0.9623166666666667, 0.9584\n",
      "Loss:  0.1221370984755436\n",
      "train acc, test acc | 0.9633833333333334, 0.9588\n",
      "Loss:  0.15001570487529053\n",
      "train acc, test acc | 0.9634833333333334, 0.96\n",
      "Loss:  0.07965706549486487\n",
      "train acc, test acc | 0.9648333333333333, 0.9591\n",
      "Loss:  0.1319565834677753\n",
      "train acc, test acc | 0.9653333333333334, 0.9604\n",
      "Loss:  0.08469388379125992\n",
      "train acc, test acc | 0.96625, 0.9608\n",
      "Loss:  0.0805242724541601\n",
      "train acc, test acc | 0.9668166666666667, 0.9607\n",
      "Loss:  0.05347784447033976\n",
      "train acc, test acc | 0.9673, 0.9618\n",
      "Loss:  0.13755881271876103\n",
      "train acc, test acc | 0.96795, 0.9617\n",
      "Loss:  0.10811288568726038\n",
      "train acc, test acc | 0.96875, 0.9624\n",
      "Loss:  0.0892448475969162\n",
      "train acc, test acc | 0.9691833333333333, 0.963\n",
      "Loss:  0.0871650786474774\n",
      "train acc, test acc | 0.9698166666666667, 0.9623\n",
      "Loss:  0.09574703655188369\n",
      "train acc, test acc | 0.9702166666666666, 0.9637\n",
      "Loss:  0.0371341734345556\n",
      "train acc, test acc | 0.9705166666666667, 0.9643\n",
      "Loss:  0.06956687047564496\n",
      "train acc, test acc | 0.9711333333333333, 0.9641\n",
      "Loss:  0.11813492486863711\n",
      "train acc, test acc | 0.9720166666666666, 0.9638\n",
      "Loss:  0.09421978370789748\n",
      "train acc, test acc | 0.9723666666666667, 0.9647\n",
      "Loss:  0.123650005477456\n",
      "train acc, test acc | 0.9722666666666666, 0.9651\n",
      "Loss:  0.1147853252971995\n",
      "train acc, test acc | 0.9728666666666667, 0.9654\n",
      "Loss:  0.0534365867976124\n",
      "train acc, test acc | 0.9736666666666667, 0.9663\n",
      "Loss:  0.11324355547738396\n",
      "train acc, test acc | 0.9738166666666667, 0.9658\n",
      "Loss:  0.0531433984378257\n",
      "train acc, test acc | 0.9741666666666666, 0.9662\n",
      "Loss:  0.04920036924391554\n",
      "train acc, test acc | 0.9743333333333334, 0.9663\n",
      "Loss:  0.11508560657603115\n",
      "train acc, test acc | 0.9748833333333333, 0.9664\n",
      "Loss:  0.07513958132083083\n",
      "train acc, test acc | 0.9751, 0.9669\n",
      "Loss:  0.08528343349642543\n",
      "train acc, test acc | 0.9754333333333334, 0.9667\n",
      "Loss:  0.06035031503296032\n",
      "train acc, test acc | 0.9757666666666667, 0.9677\n",
      "Loss:  0.09119735696039705\n",
      "train acc, test acc | 0.9762666666666666, 0.9673\n",
      "Loss:  0.09363563293958559\n",
      "train acc, test acc | 0.9765666666666667, 0.967\n",
      "Loss:  0.03747909908395414\n",
      "train acc, test acc | 0.9769833333333333, 0.9672\n",
      "Loss:  0.08600794952357389\n",
      "train acc, test acc | 0.9773833333333334, 0.9677\n",
      "Loss:  0.08806961101433075\n",
      "train acc, test acc | 0.9774166666666667, 0.9678\n",
      "Loss:  0.08732579410236968\n",
      "train acc, test acc | 0.9775, 0.9674\n",
      "Loss:  0.054864630410916\n",
      "train acc, test acc | 0.9780666666666666, 0.9685\n",
      "Loss:  0.09970040767700623\n",
      "train acc, test acc | 0.9785333333333334, 0.9684\n",
      "Loss:  0.032986201607950315\n",
      "train acc, test acc | 0.97865, 0.9683\n",
      "Loss:  0.05997809644129282\n",
      "train acc, test acc | 0.9789666666666667, 0.9686\n",
      "Loss:  0.12212853966595492\n",
      "train acc, test acc | 0.9793333333333333, 0.9689\n",
      "Loss:  0.1034619311771385\n",
      "train acc, test acc | 0.9796, 0.9685\n",
      "Loss:  0.04580230378154648\n",
      "train acc, test acc | 0.9797333333333333, 0.9686\n",
      "Loss:  0.11040412378197129\n",
      "train acc, test acc | 0.9801833333333333, 0.9688\n",
      "Loss:  0.06641321960107534\n",
      "train acc, test acc | 0.9803666666666667, 0.9697\n",
      "Loss:  0.06007452629692558\n",
      "train acc, test acc | 0.9803666666666667, 0.969\n",
      "Loss:  0.03560412867644171\n",
      "train acc, test acc | 0.9808833333333333, 0.9693\n",
      "Loss:  0.04905824858602251\n",
      "train acc, test acc | 0.9811666666666666, 0.9691\n",
      "Loss:  0.07845227166107008\n",
      "train acc, test acc | 0.9814, 0.9698\n",
      "Loss:  0.04335230636652512\n",
      "train acc, test acc | 0.9815, 0.9691\n",
      "Loss:  0.09712798549021566\n",
      "train acc, test acc | 0.98185, 0.9697\n",
      "Loss:  0.12573619976740014\n",
      "train acc, test acc | 0.9819666666666667, 0.9696\n",
      "Loss:  0.056976165272687646\n",
      "train acc, test acc | 0.98205, 0.9701\n",
      "Loss:  0.057008449499508417\n",
      "train acc, test acc | 0.982, 0.9694\n",
      "Loss:  0.049299652477064485\n",
      "train acc, test acc | 0.9822666666666666, 0.97\n",
      "Loss:  0.130862978189369\n",
      "train acc, test acc | 0.9827166666666667, 0.9709\n",
      "Loss:  0.04565811470663159\n",
      "train acc, test acc | 0.9831333333333333, 0.9705\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터\n",
    "iters_num = 50000  # 반복 횟수를 적절히 설정한다.\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100   # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 1에폭당 반복 수\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "W1, b1, W2, b2 = init_params(784, 50, 10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size) # DJ 추가 # np.arange(60000) 중에서 100개 뽑아내기\n",
    "    x_batch = x_train_reshaped[batch_mask] # DJ - (60000, 784)에서 (100,784), 즉 데이터(행)가 뽑힘\n",
    "    y_batch = y_train[batch_mask] # DJ - 동일함\n",
    "    \n",
    "    W1, b1, W2, b2, Loss = train_step(x_batch, y_batch, W1, b1, W2, b2, learning_rate=0.1, verbose=False) # DJ - 1 iteration\n",
    "\n",
    "    # 학습 경과 기록\n",
    "    train_loss_list.append(Loss)\n",
    "    \n",
    "    # 1에폭당 정확도 계산\n",
    "    if i % iter_per_epoch == 0:  # DJ - 50000번 반복되는데, 600번마다 기록을 남김\n",
    "        print('Loss: ', Loss)\n",
    "        train_acc = accuracy(W1, b1, W2, b2, x_train_reshaped, y_train)\n",
    "        test_acc = accuracy(W1, b1, W2, b2, x_test_reshaped, y_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-nevada",
   "metadata": {},
   "source": [
    "> 위의 과정을 요약하면,  \n",
    "> - 60000개의 데이터에서  \n",
    "> - 미니배치로 100개씩 랜덤으로 뽑는데(중복 허용)\n",
    "> - 50000번을 학습해볼 거임  \n",
    "> - 근데 600번째마다 기록을 남길 것이다.\n",
    "> - 즉 랜덤으로 뽑힌 100개의 데이터로 50000번 학습을 돌려볼 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bronze-violin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 6 \n",
    "\n",
    "# Accuracy 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "accomplished-michigan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss 그래프 그리기\n",
    "x = np.arange(len(train_loss_list))\n",
    "plt.plot(x, train_loss_list, label='train acc')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.ylim(0, 3.0)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-crown",
   "metadata": {},
   "source": [
    "> loss는 50000번의 학습 내내 리스트에 추가했고,  \n",
    "> accuracy는 600번째마다만 해서  \n",
    "> x축 값이 loss 그래프와 accuracy 그래프가 다르다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
